{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Tutorial - Code Companion\n",
    "\n",
    "This notebook contains all the code used to generate figures and demonstrations for the clustering tutorial.\n",
    "\n",
    "**GitHub Repository**: [Insert your repository link here]\n",
    "\n",
    "## References\n",
    "\n",
    "1. Arthur, D., & Vassilvitskii, S. (2007). k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms (pp. 1027-1035).\n",
    "2. Pedregosa, F., et al. (2011). Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), 2825-2830.\n",
    "3. MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations.\n",
    "4. Lloyd, S. (1982). Least squares quantization in PCM. IEEE transactions on information theory, 28(2), 129-137."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset with overlapping clusters\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, n_features=2, \n",
    "                       cluster_std=1.5, random_state=42)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Random initialization variability\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "colors = ['#0173B2', '#DE8F05', '#029E73', '#CC78BC']\n",
    "\n",
    "for idx in range(6):\n",
    "    kmeans = KMeans(n_clusters=4, init='random', n_init=1, random_state=idx)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    for cluster in range(4):\n",
    "        mask = labels == cluster\n",
    "        axes[idx].scatter(X[mask, 0], X[mask, 1], c=colors[cluster], \n",
    "                         s=30, alpha=0.6, edgecolors='black', linewidth=0.3)\n",
    "    \n",
    "    axes[idx].scatter(kmeans.cluster_centers_[:, 0], \n",
    "                     kmeans.cluster_centers_[:, 1],\n",
    "                     c='red', s=200, marker='X', edgecolors='black', \n",
    "                     linewidth=2, label='Centroids')\n",
    "    \n",
    "    axes[idx].set_title(f\"Run {idx+1} - Inertia: {kmeans.inertia_:.1f}\", fontsize=11)\n",
    "    axes[idx].set_xlabel('Feature 1')\n",
    "    axes[idx].set_ylabel('Feature 2')\n",
    "\n",
    "plt.suptitle('Random Initialization: 6 Different Runs Show Inconsistent Results', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_random_init.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: K-Means++ initialization comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Worst random result\n",
    "random_results = []\n",
    "for i in range(20):\n",
    "    km = KMeans(n_clusters=4, init='random', n_init=1, random_state=i)\n",
    "    km.fit(X)\n",
    "    random_results.append((km.inertia_, km.cluster_centers_, km.labels_))\n",
    "worst_random = max(random_results, key=lambda x: x[0])\n",
    "\n",
    "for cluster in range(4):\n",
    "    mask = worst_random[2] == cluster\n",
    "    axes[0].scatter(X[mask, 0], X[mask, 1], c=colors[cluster], \n",
    "                   s=40, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].scatter(worst_random[1][:, 0], worst_random[1][:, 1],\n",
    "               c='red', s=250, marker='X', edgecolors='black', \n",
    "               linewidth=2.5, label='Centroids')\n",
    "axes[0].set_title(f'Random Init (worst case)\\nInertia: {worst_random[0]:.1f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].legend()\n",
    "\n",
    "# K-means++ result\n",
    "kmeans_pp = KMeans(n_clusters=4, init='k-means++', n_init=10, random_state=42)\n",
    "labels_pp = kmeans_pp.fit_predict(X)\n",
    "\n",
    "for cluster in range(4):\n",
    "    mask = labels_pp == cluster\n",
    "    axes[1].scatter(X[mask, 0], X[mask, 1], c=colors[cluster], \n",
    "                   s=40, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].scatter(kmeans_pp.cluster_centers_[:, 0], \n",
    "               kmeans_pp.cluster_centers_[:, 1],\n",
    "               c='red', s=250, marker='X', edgecolors='black', \n",
    "               linewidth=2.5, label='Centroids')\n",
    "axes[1].set_title(f'K-Means++ Init\\nInertia: {kmeans_pp.inertia_:.1f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Improvement: {(worst_random[0] - kmeans_pp.inertia_) / worst_random[0] * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Impact of n_init parameter\n",
    "n_init_values = [1, 5, 10, 20, 50]\n",
    "n_trials = 30\n",
    "\n",
    "random_results_ninit = {}\n",
    "kmpp_results_ninit = {}\n",
    "\n",
    "for n_init in n_init_values:\n",
    "    random_inertias = []\n",
    "    kmpp_inertias = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        km_r = KMeans(n_clusters=4, init='random', n_init=n_init, random_state=trial)\n",
    "        km_r.fit(X)\n",
    "        random_inertias.append(km_r.inertia_)\n",
    "        \n",
    "        km_p = KMeans(n_clusters=4, init='k-means++', n_init=n_init, random_state=trial)\n",
    "        km_p.fit(X)\n",
    "        kmpp_inertias.append(km_p.inertia_)\n",
    "    \n",
    "    random_results_ninit[n_init] = random_inertias\n",
    "    kmpp_results_ninit[n_init] = kmpp_inertias\n",
    "\n",
    "# Create box plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "random_data = [random_results_ninit[n] for n in n_init_values]\n",
    "kmpp_data = [kmpp_results_ninit[n] for n in n_init_values]\n",
    "\n",
    "bp1 = axes[0].boxplot(random_data, labels=n_init_values, patch_artist=True)\n",
    "for patch in bp1['boxes']:\n",
    "    patch.set_facecolor('#0173B2')\n",
    "    patch.set_alpha(0.6)\n",
    "axes[0].set_xlabel('n_init parameter', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Inertia', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Random Initialization', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "bp2 = axes[1].boxplot(kmpp_data, labels=n_init_values, patch_artist=True)\n",
    "for patch in bp2['boxes']:\n",
    "    patch.set_facecolor('#DE8F05')\n",
    "    patch.set_alpha(0.6)\n",
    "axes[1].set_xlabel('n_init parameter', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Inertia', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('K-Means++ Initialization', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Impact of n_init Parameter on Result Consistency', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure3_ninit.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Customer segmentation example\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create realistic customer segments\n",
    "seg1_spend = np.random.normal(500, 100, 100)\n",
    "seg1_freq = np.random.normal(2, 0.5, 100)\n",
    "\n",
    "seg2_spend = np.random.normal(100, 30, 150)\n",
    "seg2_freq = np.random.normal(15, 3, 150)\n",
    "\n",
    "seg3_spend = np.random.normal(250, 50, 200)\n",
    "seg3_freq = np.random.normal(8, 2, 200)\n",
    "\n",
    "seg4_spend = np.random.normal(1000, 200, 50)\n",
    "seg4_freq = np.random.normal(6, 1.5, 50)\n",
    "\n",
    "customer_spend = np.concatenate([seg1_spend, seg2_spend, seg3_spend, seg4_spend])\n",
    "customer_freq = np.concatenate([seg1_freq, seg2_freq, seg3_freq, seg4_freq])\n",
    "X_customers = np.column_stack([customer_spend, customer_freq])\n",
    "\n",
    "# Scale and cluster\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_customers)\n",
    "\n",
    "kmeans_customer = KMeans(n_clusters=4, init='k-means++', n_init=10, random_state=42)\n",
    "labels_customer = kmeans_customer.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for cluster in range(4):\n",
    "    mask = labels_customer == cluster\n",
    "    ax.scatter(X_customers[mask, 0], X_customers[mask, 1], \n",
    "              c=colors[cluster], s=40, alpha=0.6, \n",
    "              edgecolors='black', linewidth=0.3, \n",
    "              label=f'Segment {cluster+1}')\n",
    "\n",
    "centroids = scaler.inverse_transform(kmeans_customer.cluster_centers_)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1],\n",
    "          c='red', s=300, marker='X', edgecolors='black', \n",
    "          linewidth=2.5, label='Centroids', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Monthly Spend ($)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Purchase Frequency (visits/month)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Customer Segmentation Using K-Means++', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure4_customer_segmentation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print segment characteristics\n",
    "print(\"\\nSegment Characteristics:\")\n",
    "for i in range(4):\n",
    "    mask = labels_customer == i\n",
    "    print(f\"\\nSegment {i+1}:\")\n",
    "    print(f\"  Size: {np.sum(mask)} customers\")\n",
    "    print(f\"  Avg Spend: ${centroids[i, 0]:.2f}\")\n",
    "    print(f\"  Avg Frequency: {centroids[i, 1]:.2f} visits/month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices function\n",
    "def apply_kmeans_clustering(X, n_clusters=4):\n",
    "    \"\"\"\n",
    "    Apply K-Means clustering with best practices.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Input data\n",
    "    n_clusters : int\n",
    "        Number of clusters to form\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing model, labels, and metrics\n",
    "    \"\"\"\n",
    "    # Step 1: Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Step 2: Apply K-Means with best practices\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        init='k-means++',      # Use intelligent initialization\n",
    "        n_init=10,             # Try 10 different initializations\n",
    "        max_iter=300,          # Maximum iterations per run\n",
    "        random_state=42        # For reproducibility\n",
    "    )\n",
    "    \n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Step 3: Calculate quality metrics\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    return {\n",
    "        'model': kmeans,\n",
    "        'labels': labels,\n",
    "        'scaler': scaler,\n",
    "        'inertia': kmeans.inertia_,\n",
    "        'silhouette': silhouette\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "results = apply_kmeans_clustering(X_customers, n_clusters=4)\n",
    "print(f\"Silhouette Score: {results['silhouette']:.3f}\")\n",
    "print(f\"Inertia: {results['inertia']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. The variability of random initialization\n",
    "2. The consistency improvement with K-Means++\n",
    "3. The impact of the n_init parameter\n",
    "4. A practical customer segmentation example\n",
    "5. Best practices for applying K-Means clustering\n",
    "\n",
    "All figures are saved as PNG files for use in the tutorial document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
